# src/preprocess.py

import pandas as pd
import re
import os

# 1. æŒ‡å®šæ¬„ä½åç¨±ï¼ˆSentiment140 åŸå§‹æ¬„ä½ï¼‰
columns = ["target", "ids", "date", "flag", "user", "text"]

# 2. è®€å–åŸå§‹æª”æ¡ˆï¼ˆæŒ‡å®šç·¨ç¢¼ ISO-8859-1ï¼‰
input_path = "data/raw/training.1600000.processed.noemoticon.csv"
df = pd.read_csv(input_path, encoding="ISO-8859-1", names=columns)
print(df)

# # 3. åªä¿ç•™å¿…è¦æ¬„ä½
# df = df[["text", "target"]]

# # 4. æŠŠ 4ï¼ˆæ­£å‘ï¼‰è½‰ç‚º 1ï¼Œ0ï¼ˆè² å‘ï¼‰ä¿æŒä¸è®Š
# df["target"] = df["target"].apply(lambda x: 1 if x == 4 else 0)

# # 5. å®šç¾©æ¸…ç†å‡½å¼
# def clean_text(text):
#     text = re.sub(r"http\S+", "", text)      # ç§»é™¤ç¶²å€
#     text = re.sub(r"@\w+", "", text)         # ç§»é™¤æåŠ
#     text = re.sub(r"#\w+", "", text)         # ç§»é™¤ hashtag
#     text = re.sub(r"[^a-zA-Z0-9\s]", "", text)  # ç§»é™¤ç‰¹æ®Šå­—å…ƒ
#     return text.lower().strip()

# # 6. æ¸…ç†ç•™è¨€å…§å®¹
# df["text"] = df["text"].astype(str).apply(clean_text)

# # 7. ç§»é™¤ç©ºç™½æˆ–é‡è¤‡ç•™è¨€
# df = df[df["text"] != ""]
# df = df.drop_duplicates(subset="text")

# # 8. å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
# output_dir = "data/processed"
# os.makedirs(output_dir, exist_ok=True)

# # 9. è¼¸å‡ºæ¸…ç†å¾Œè³‡æ–™
# output_path = os.path.join(output_dir, "sentiment140_clean.csv")
# df.to_csv(output_path, index=False)

# print(f"âœ… å·²å®Œæˆå‰è™•ç†ï¼Œå„²å­˜æ–¼ï¼š{output_path}")
# print(f"ğŸ‘‰ å…± {len(df)} ç­†è³‡æ–™")
